"""add_pgroonga_index_and_remove_vector

Revision ID: 9ef080b3f75c
Revises: b2c3d4e5f6a7
Create Date: 2025-09-12 22:11:18.606491

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '9ef080b3f75c'
down_revision = 'b2c3d4e5f6a7'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    try:
        with op.batch_alter_table('chinese_texts', schema=None) as batch_op:
            batch_op.drop_index(batch_op.f('pgroonga_content_index'), postgresql_using='pgroonga')
    except Exception:
        pass # Index might not exist, ignore

    try:
        op.drop_table('chinese_texts')
    except Exception:
        pass # Table might not exist, ignore

    with op.batch_alter_table('documents', schema=None) as batch_op:
        try:
            batch_op.drop_index(batch_op.f('idx_documents_file_name_gin'), postgresql_ops={'file_name': 'gin_trgm_ops'}, postgresql_using='gin')
        except Exception:
            pass
        try:
            batch_op.drop_index(batch_op.f('idx_documents_markdown_content_gin'), postgresql_ops={'markdown_content': 'gin_trgm_ops'}, postgresql_using='gin')
        except Exception:
            pass
        try:
            batch_op.drop_index(batch_op.f('pgrn_idx_documents_file_name'), postgresql_using='pgroonga')
        except Exception:
            pass
        try:
            batch_op.drop_index(batch_op.f('pgrn_idx_documents_markdown_content'), postgresql_using='pgroonga')
        except Exception:
            pass
        try:
            batch_op.drop_column('search_vector')
        except Exception:
            pass
    
    # Create a composite PGroonga index for efficient full-text search
    op.execute("""
        DROP INDEX IF EXISTS idx_pgroonga_documents_composite;
    """)
    op.execute("""
        CREATE INDEX idx_pgroonga_documents_composite ON documents
        USING pgroonga (file_name, content)
        WITH (
            tokenizer = 'TokenNgram',
            normalizer = 'NormalizerAuto',
            token_filters = 'TokenFilterStopWord'
        );
    """)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop the PGroonga index
    op.execute("DROP INDEX idx_pgroonga_documents_composite;")
    
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.add_column(sa.Column('search_vector', postgresql.TSVECTOR(), autoincrement=False, nullable=True))
        batch_op.create_index(batch_op.f('pgrn_idx_documents_markdown_content'), ['markdown_content'], unique=False, postgresql_using='pgroonga')
        batch_op.create_index(batch_op.f('pgrn_idx_documents_file_name'), ['file_name'], unique=False, postgresql_using='pgroonga')
        batch_op.create_index(batch_op.f('idx_documents_markdown_content_gin'), ['markdown_content'], unique=False, postgresql_ops={'markdown_content': 'gin_trgm_ops'}, postgresql_using='gin')
        batch_op.create_index(batch_op.f('idx_documents_file_name_gin'), ['file_name'], unique=False, postgresql_ops={'file_name': 'gin_trgm_ops'}, postgresql_using='gin')

    op.create_table('chinese_texts',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('content', sa.TEXT(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('chinese_texts_pkey'))
    )
    with op.batch_alter_table('chinese_texts', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('pgroonga_content_index'), ['content'], unique=False, postgresql_using='pgroonga')

    # ### end Alembic commands ###
